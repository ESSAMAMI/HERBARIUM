{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, BatchNormalization, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import tensorflow as tf\n",
    "# imports for cpu use\n",
    "import sys\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TEST = 'D:/cours/quatrième année/Deep learning/Projet kaggle/nybg2020/test/'\n",
    "DIR_TRAIN = 'D:/cours/quatrième année/Deep learning/Projet kaggle/nybg2020/train/'\n",
    "META_DATA_TRAIN = DIR_TRAIN+'metadata.json'\n",
    "META_DATA_TEST = DIR_TEST+'metadata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all devices\n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11436057962408791607\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3144653209\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3415042430450911012\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "] \n",
      "\n",
      "GPU\n",
      "Utiliser son cpu en utilisant des with tf.device('/cpu:0'):\n"
     ]
    }
   ],
   "source": [
    "#CHECK HOW MANY GPU ON PC\n",
    "# Check if the server/ instance is having GPU/ CPU from python code\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# device_lib.list_local_devices()     ## this command list all the processing device GPU and CPU\n",
    "\n",
    "print(\"all devices\\n\", device_lib.list_local_devices(), '\\n')\n",
    "device_name = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "if device_name[0] == \"/device:GPU:0\":\n",
    "    device_name = \"/gpu:0\"\n",
    "    print('GPU')\n",
    "else:\n",
    "    print('CPU')\n",
    "\n",
    "print(\"Utiliser son cpu en utilisant des with tf.device('/cpu:0'):\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTRAIN_PATH = \\'D:/cours/quatrième année/Deep learning/Projet kaggle/nybg2020/train_separated/\\'\\ncnt = 0\\nfor category in os.listdir(TRAIN_PATH):\\n    if len(os.listdir(TRAIN_PATH+category)) < 10:\\n        cnt += 1\\n        open_dir = (os.listdir(TRAIN_PATH+category))\\n        print(category)\\n        for image in open_dir:\\n            try:\\n                img = read_img(TRAIN_PATH+str(category)+\\'/\\'+image)\\n                x = img_to_array(img)\\n                x = x.reshape((1,) + x.shape)\\n                i = 0\\n                for batch in image_gen.flow(x, batch_size=1, save_to_dir=TRAIN_PATH+str(category)+\\'/\\', save_prefix=\\'datagen\\', save_format=\"jpg\"):\\n                    i+=1\\n                    if i > 10:\\n                        break\\n            except Exception as e:\\n                print(\"image caused error => \" % image)\\n                break\\nprint(\"Nombre de categroies avec moins 10 images %s\" % (cnt))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TRAIN_PATH = 'D:/cours/quatrième année/Deep learning/Projet kaggle/nybg2020/train_separated/'\n",
    "cnt = 0\n",
    "for category in os.listdir(TRAIN_PATH):\n",
    "    if len(os.listdir(TRAIN_PATH+category)) < 10:\n",
    "        cnt += 1\n",
    "        open_dir = (os.listdir(TRAIN_PATH+category))\n",
    "        print(category)\n",
    "        for image in open_dir:\n",
    "            try:\n",
    "                img = read_img(TRAIN_PATH+str(category)+'/'+image)\n",
    "                x = img_to_array(img)\n",
    "                x = x.reshape((1,) + x.shape)\n",
    "                i = 0\n",
    "                for batch in image_gen.flow(x, batch_size=1, save_to_dir=TRAIN_PATH+str(category)+'/', save_prefix='datagen', save_format=\"jpg\"):\n",
    "                    i+=1\n",
    "                    if i > 10:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(\"image caused error => \" % image)\n",
    "                break\n",
    "print(\"Nombre de categroies avec moins 10 images %s\" % (cnt))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- annotations 1030747\n",
      "- categories 32094\n",
      "- images 1030747\n",
      "- info 6\n",
      "- licenses 1\n",
      "- regions 4\n",
      "================================\n",
      "- images 138292\n",
      "- info 6\n",
      "- licenses 1\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    with open(META_DATA_TRAIN, 'r') as json_file:\n",
    "        data_train = json.load(json_file)\n",
    "        for key in data_train:\n",
    "            print(\"-\",key, len(data_train[key]))\n",
    "    print(\"================================\")\n",
    "    with open(META_DATA_TEST, 'r') as json_file2:\n",
    "        data_test = json.load(json_file2)\n",
    "        for key in data_test:\n",
    "            print(\"-\",key, len(data_test[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============= TESTS THEORIE MINI APPRENTISSAGE ============== #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ================================== COLLECT TRAIN DATA ================================== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>id</th>\n",
       "      <th>license</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/156/72/354106.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>354106</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/115/24/818566.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>818566</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/115/24/750704.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>750704</td>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name  height      id  license  width\n",
       "0  images/156/72/354106.jpg    1000  354106        1    661\n",
       "1  images/115/24/818566.jpg    1000  818566        1    661\n",
       "2  images/115/24/750704.jpg    1000  750704        1    661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    df_images = pd.DataFrame(data_train['images'])\n",
    "    display(df_images.head(3))\n",
    "    df_categories = pd.DataFrame(data_train['categories'])\n",
    "    df_annotations = pd.DataFrame(data_train['annotations'])\n",
    "    assert len(df_annotations) == len(df_images)\n",
    "    df_images_annotations = pd.merge(df_images, df_annotations, left_on='id', right_on='image_id', how='right').drop('image_id', axis=1)\n",
    "    df_images_annotations = df_images_annotations.sort_values(['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    df_families = df_categories.drop('genus', axis=1).drop('id', axis=1).drop('name', axis=1).drop_duplicates().reset_index().drop('index', axis=1)\n",
    "    df_families.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    df_images_infos = pd.merge(df_images_annotations, df_categories, left_on='category_id', right_on='id', how='right')\\\n",
    "                        .drop('height', axis=1).drop('id_x', axis=1).drop('license', axis=1).drop('width', axis=1)\\\n",
    "                        .drop('category_id', axis=1).drop('id_y', axis=1).drop('region_id', axis=1).drop('name', axis=1)\n",
    "\n",
    "    df_images_infos = df_images_infos.rename(columns={\"id\":\"category_id\"})\n",
    "\n",
    "    df_images_infos.sort_values(by='family', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ================================== COLLECT TEST DATA ================================== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/104/104891.jpg</td>\n",
       "      <td>104891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/018/18029.jpg</td>\n",
       "      <td>18029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/035/35151.jpg</td>\n",
       "      <td>35151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file_name      id\n",
       "0  images/104/104891.jpg  104891\n",
       "1   images/018/18029.jpg   18029\n",
       "2   images/035/35151.jpg   35151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    df_images = pd.DataFrame(data_test['images']).drop('height', axis=1).drop('width', axis=1).drop('license', axis=1)\n",
    "    display(df_images.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======================================= SAVE DATA ====================================== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    df_images_infos.to_csv('D:/cours/quatrième année/Deep learning/Projet kaggle/full_train_data.csv', index=False)\n",
    "    df_images.to_csv('D:/cours/quatrième année/Deep learning/Projet kaggle/full_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ===================================== EXPLORE DATA ==================================== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>280.094565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>763.668945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14490.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category_id\n",
       "count   3680.000000\n",
       "mean     280.094565\n",
       "std      763.668945\n",
       "min        2.000000\n",
       "25%       12.000000\n",
       "50%       54.000000\n",
       "75%      198.000000\n",
       "max    14490.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    family = df_images_infos[['family', 'genus', 'category_id']].groupby(['family', 'genus']).count()\n",
    "    display(family.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==================================== MODEL CREATION =================================== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    in_out_size = (14*14) + 3\n",
    "    img_shape = 14\n",
    "    def xavier(shape, dtype=None):\n",
    "        return np.random.rand(*shape)*np.sqrt(1/in_out_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    def fg_model(shape, lr=0.001):\n",
    "        '''Family-Genus model receives an image and outputs two integers indicating both the family and genus index.'''\n",
    "        i = Input(shape)\n",
    "        \n",
    "        #MLP\n",
    "        #x = Flatten()(i)\n",
    "            \n",
    "        #x = Dense(1024, activation='relu', name='dense_1', kernel_initializer=xavier)(x)\n",
    "        #x = Dense(512, activation='relu', name='dense_2', kernel_initializer=xavier)(x)\n",
    "        #x = Dense(256, activation='relu', name='dense_3', kernel_initializer=xavier)(x)\n",
    "        \n",
    "        '''\n",
    "        #CNN NEAR KAGGLE \n",
    "        x = Conv2D(3, (3, 3), activation='relu', padding='same', kernel_initializer=xavier)(i)\n",
    "        x = Conv2D(3, (3, 3), activation='relu', padding='same', kernel_initializer=xavier)(x)\n",
    "        x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer=xavier)(x)\n",
    "        x = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_initializer=xavier)(x)\n",
    "        x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        x = Flatten()(x)\n",
    "        '''\n",
    "        \n",
    "        #CNN POWERFULL\n",
    "        x = Conv2D(32, (3, 3), activation='relu', kernel_initializer=xavier, padding='same')(i)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(32, (3, 3), activation='relu', kernel_initializer=xavier, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D((2, 2))(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=xavier, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=xavier, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D((2, 2))(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu', kernel_initializer=xavier, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu', kernel_initializer=xavier, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D((2, 2))(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu', kernel_initializer=xavier)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "            \n",
    "        \n",
    "        o1 = Dense(310, activation='softmax', name='family', kernel_initializer=xavier)(x)\n",
    "\n",
    "        o2 = concatenate([o1, x])\n",
    "        o2 = Dense(3678, activation='softmax', name='genus', kernel_initializer=xavier)(o2)\n",
    "\n",
    "        o3 = concatenate([o1, o2, x])\n",
    "        o3 = Dense(32094, activation='softmax', name='category_id', kernel_initializer=xavier)(o3)\n",
    "\n",
    "        x = Model(inputs=i, outputs=[o1, o2, o3])\n",
    "\n",
    "        opt = Adam(lr=lr, amsgrad=True)\n",
    "        x.compile(optimizer=opt, loss=['sparse_categorical_crossentropy', \n",
    "                                       'sparse_categorical_crossentropy', \n",
    "                                       'sparse_categorical_crossentropy'],\n",
    "                     metrics=['accuracy'])\n",
    "        return x\n",
    "\n",
    "    model = fg_model((img_shape, img_shape, 3))\n",
    "    model.summary()\n",
    "    #plot_model(model, to_file='full_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    name_of_model = \"cnn_6\"\n",
    "    plot_model(model, to_file=name_of_model + '_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==================================== DATA GENERATOR =================================== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                         featurewise_std_normalization=False,\n",
    "                                         rotation_range=180,\n",
    "                                         width_shift_range=0.1,\n",
    "                                         height_shift_range=0.1,\n",
    "                                         zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    m = df_images_infos[['file_name', 'family', 'genus', 'category_id']]\n",
    "    fam = m.family.unique().tolist()\n",
    "    m.family = m.family.map(lambda x: fam.index(x))\n",
    "    gen = m.genus.unique().tolist()\n",
    "    m.genus = m.genus.map(lambda x: gen.index(x))\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KILL THE NAN VALUE IN M TO PREVENT BUGS\")\n",
    "print(type(m))\n",
    "na = m.file_name.isna()\n",
    "keep = [x for x in range(m.shape[0]) if not na[x]]\n",
    "m = m.iloc[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train = train[:400000]\n",
    "verif = verif[:100000]\n",
    "verif.head(5)\n",
    "store_type = verif.dtypes\n",
    "print(\"before ver \", store_type)\n",
    "verif = verif.astype(str)\n",
    "print(\"after ver \", verif.dtypes)\n",
    "\n",
    "store_type_2 = train.dtypes\n",
    "print(\"before train \", store_type_2)\n",
    "train = train.astype(str)\n",
    "print(\"after train \", train.dtypes)\n",
    "\n",
    "print(\"train x_col type = \", type(train['file_name'].values[0]))\n",
    "print(\"test x_col type = \", type(verif['file_name'].values[0]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========================================= TRAIN ======================================== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, verif = tts(m, test_size=0.2, shuffle=True, random_state=17)\n",
    "train = train[:400000]\n",
    "verif = verif[:100000]\n",
    "shape = (img_shape, img_shape, 3)\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "\n",
    "print(\"after train \\n\", train.dtypes)\n",
    "print(\"\\nfile name = \", type(train['file_name']))\n",
    "\n",
    "model = fg_model(shape, 0.007)\n",
    "\n",
    "#Disable the last two output layers for training the Family\n",
    "for layers in model.layers:\n",
    "    if layers.name == 'genus' or layers.name=='category_id':\n",
    "        layers.trainable = False\n",
    "\n",
    "#Train Family for 2 epochs\n",
    "model.fit_generator(train_datagen.flow_from_dataframe(dataframe=train,\n",
    "                                                      directory=DIR_TRAIN,\n",
    "                                                      x_col=\"file_name\",\n",
    "                                                      y_col=[\"family\", \"genus\", \"category_id\"],\n",
    "                                                      target_size=(img_shape, img_shape),\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      class_mode='multi_output'),\n",
    "                    validation_data=train_datagen.flow_from_dataframe(\n",
    "                        dataframe=verif,\n",
    "                        directory=DIR_TRAIN,\n",
    "                        x_col=\"file_name\",\n",
    "                        y_col=[\"family\", \"genus\", \"category_id\"],\n",
    "                        target_size=(img_shape, img_shape),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='multi_output'),\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=len(train)//batch_size,\n",
    "                    validation_steps=len(verif)//batch_size,\n",
    "                    verbose=1,\n",
    "                    workers=8,\n",
    "                    use_multiprocessing=False)\n",
    "\n",
    "#Reshuffle the inputs\n",
    "train, verif = tts(m, test_size=0.2, shuffle=True, random_state=17)\n",
    "train = train[:400000]\n",
    "verif = verif[:100000]\n",
    "\n",
    "#Make the Genus layer Trainable\n",
    "for layers in model.layers:\n",
    "    if layers.name == 'genus':\n",
    "        layers.trainable = True\n",
    "        \n",
    "#Train Family and Genus for 2 epochs\n",
    "model.fit_generator(train_datagen.flow_from_dataframe(dataframe=train,\n",
    "                                                      directory=DIR_TRAIN,\n",
    "                                                      x_col=\"file_name\",\n",
    "                                                      y_col=[\"family\", \"genus\", \"category_id\"],\n",
    "                                                      target_size=(img_shape, img_shape),\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      class_mode='multi_output'),\n",
    "                    validation_data=train_datagen.flow_from_dataframe(\n",
    "                        dataframe=verif,\n",
    "                        directory=DIR_TRAIN,\n",
    "                        x_col=\"file_name\",\n",
    "                        y_col=[\"family\", \"genus\", \"category_id\"],\n",
    "                        target_size=(img_shape, img_shape),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='multi_output'),\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=len(train)//batch_size,\n",
    "                    validation_steps=len(verif)//batch_size,\n",
    "                    verbose=1,\n",
    "                    workers=8,\n",
    "                    use_multiprocessing=False)\n",
    "\n",
    "#Reshuffle the inputs\n",
    "train, verif = tts(m, test_size=0.2, shuffle=True, random_state=17)\n",
    "train = train[:400000]\n",
    "verif = verif[:100000]\n",
    "\n",
    "#Make the category_id layer Trainable\n",
    "for layers in model.layers:\n",
    "    if layers.name == 'category_id':\n",
    "        layers.trainable = True\n",
    "        \n",
    "#Train them all for 2 epochs\n",
    "model.fit_generator(train_datagen.flow_from_dataframe(dataframe=train,\n",
    "                                                      directory=DIR_TRAIN,\n",
    "                                                      x_col=\"file_name\",\n",
    "                                                      y_col=[\"family\", \"genus\", \"category_id\"],\n",
    "                                                      target_size=(img_shape, img_shape),\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      class_mode='multi_output'),\n",
    "                    validation_data=train_datagen.flow_from_dataframe(\n",
    "                        dataframe=verif,\n",
    "                        directory=DIR_TRAIN,\n",
    "                        x_col=\"file_name\",\n",
    "                        y_col=[\"family\", \"genus\", \"category_id\"],\n",
    "                        target_size=(img_shape, img_shape),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='multi_output'),\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=len(train)//batch_size,\n",
    "                    validation_steps=len(verif)//batch_size,\n",
    "                    verbose=1,\n",
    "                    workers=8,\n",
    "                    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(name_of_model + '_fg_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======================================== PREDICT ======================================= ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames.\n",
      "157/157 [==============================] - 86s 547ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-99c4c6874a38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nombres de classes différentes prédites :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predicted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    batch_size = 32\n",
    "    #name_of_model = \"cnn_5\"\n",
    "    train_model = tf.keras.models.load_model(name_of_model+'_fg_model.h5', custom_objects={\"xavier\":xavier})\n",
    "\n",
    "    test_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                      featurewise_std_normalization=False)\n",
    "\n",
    "    generator = test_datagen.flow_from_dataframe(\n",
    "            dataframe = df_images.iloc[:5000], #Limiting the test to the first 10,000 items\n",
    "            directory = DIR_TEST,\n",
    "            x_col = 'file_name',\n",
    "            target_size=(img_shape, img_shape),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=None,  # only data, no labels\n",
    "            shuffle=False)\n",
    "\n",
    "    family, genus, category = train_model.predict_generator(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====================================== SUBMISSION ====================================== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104891</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18029</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35151</td>\n",
       "      <td>22941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124144</td>\n",
       "      <td>6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24649</td>\n",
       "      <td>22941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138287</th>\n",
       "      <td>32738</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138288</th>\n",
       "      <td>16804</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138289</th>\n",
       "      <td>113662</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138290</th>\n",
       "      <td>86100</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138291</th>\n",
       "      <td>28731</td>\n",
       "      <td>23718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Predicted\n",
       "0       104891       5221\n",
       "1        18029       5221\n",
       "2        35151      22941\n",
       "3       124144       6983\n",
       "4        24649      22941\n",
       "...        ...        ...\n",
       "138287   32738      23718\n",
       "138288   16804      23718\n",
       "138289  113662      23718\n",
       "138290   86100      23718\n",
       "138291   28731      23718\n",
       "\n",
       "[138292 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombres de classes différentes prédites : 20\n"
     ]
    }
   ],
   "source": [
    "name_of_model = \"cnn_5\"\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = df_images.id\n",
    "sub['Id'] = sub['Id'].astype('int32')\n",
    "\n",
    "sub['Predicted'] = np.concatenate([np.argmax(category, axis=1), 23718*np.ones((len(df_images.id)-len(category)))], axis=0)\n",
    "sub['Predicted'] = sub['Predicted'].astype('int32')\n",
    "display(sub)\n",
    "sub.to_csv(name_of_model+'_category_submission.csv', index=False)\n",
    "print(\"nombres de classes différentes prédites :\", sub['Predicted'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Predicted'] = np.concatenate([np.argmax(family, axis=1), np.zeros((len(df_images.id)-len(family)))], axis=0)\n",
    "sub['Predicted'] = sub['Predicted'].astype('int32')\n",
    "display(sub)\n",
    "sub.to_csv(name_of_model+'cnn_5_family_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Predicted'] = np.concatenate([np.argmax(genus, axis=1), np.zeros((len(df_images.id)-len(genus)))], axis=0)\n",
    "sub['Predicted'] = sub['Predicted'].astype('int32')\n",
    "display(sub)\n",
    "sub.to_csv(name_of_model+'_genus_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "total = end_time - start_time\n",
    "h = total//3600\n",
    "m = (total%3600)//60\n",
    "s = total%60\n",
    "print(\"Total time spent: %i hours, %i minutes, and %i seconds\" %(h, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
